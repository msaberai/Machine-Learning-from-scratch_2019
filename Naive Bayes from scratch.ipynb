{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes from scratch\n",
    "\n",
    "Problem:  Implement a spam filter based on the Naive Bayes classifier.\n",
    "\n",
    "This implementation features: \n",
    " - data_loader for the data format (also can split data into train and test).\n",
    " - naive_bayes algorithm which classifies the test data and calculates metrics\n",
    " - not optimized code. I rather focuses on step by step calculation to maximize understandability\n",
    " \n",
    "Note: Throughout this implementation, Spam is labeled with 1 and Ham is labeled with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pn\n",
    "import os\n",
    "import math as m\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_tansformer:                  # data loader which load all the data into one matrix \n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        self.data = self.open_files()\n",
    "        \n",
    "    def open_files(self):               #opens all the files and combines them\n",
    "        documents = []\n",
    "        titles = []\n",
    "        for filename in os.listdir(self.path):\n",
    "            for file in os.listdir(self.path + \"/\" + filename):\n",
    "                titles.append(str(file))\n",
    "                data = open(self.path + \"/\" + filename + \"/\" + str(file),\"r+\")\n",
    "                data = data.read()\n",
    "                data = data.replace(\"\\n\",\" \")\n",
    "                data = data.replace(\"Subject:\",\"\")\n",
    "                data = data.split(\" \")\n",
    "                num = []\n",
    "                for x in range (len(data)):\n",
    "                    if data[x] == \"\":\n",
    "                        pass\n",
    "                    else: \n",
    "                        num.append(int(data[x]))\n",
    "                documents.append(num)\n",
    "            numL = []\n",
    "            for y in titles: \n",
    "                if \"spmsg\"  in y:\n",
    "                    numL.append(1)\n",
    "                elif \"legit\" in y: \n",
    "                    numL.append(0)\n",
    "                    \n",
    "        documents = np.expand_dims(np.array(documents),axis= 1)\n",
    "        numL = np.expand_dims(np.array(numL),axis= 1)\n",
    "        return np.concatenate((documents,numL),axis = 1)\n",
    "    \n",
    "    def split(self, percent = 0.3):              #splits the data into train and test based on a percentage\n",
    "        data = np.random.shuffle(self.data)\n",
    "        test = self.data[:int(0.3*len(self.data))]\n",
    "        train = self.data[int(0.3*len(self.data)):]\n",
    "        return train,test       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naive_bayes:               #main naive bayes classifier class\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def split_classes(self,data):\n",
    "        spam = []\n",
    "        ham = []\n",
    "        for x in data:\n",
    "            if x[1] == 1:\n",
    "                spam.append(x)\n",
    "            elif x[1] == 0:\n",
    "                ham.append(x)\n",
    "        return np.array(spam), np.array(ham)\n",
    "    \n",
    "    def create_word_dict(self):                #counts the word occurences for both classes\n",
    "        spamDic = {}\n",
    "        hamDic = {}\n",
    "        spamCount = 0 \n",
    "        hamCount = 0\n",
    "        spamV = 0\n",
    "        hamV = 0 \n",
    "        for x in range (len(self.spam)): \n",
    "            for y in range(len(self.spam[x][0])):\n",
    "                spamCount +=1 \n",
    "                if self.spam[x][0][y] in spamDic: \n",
    "                    spamDic[self.spam[x][0][y]] +=1\n",
    "                else: \n",
    "                    spamV +=1\n",
    "                    spamDic[self.spam[x][0][y]] =1\n",
    "        for x in range (len(self.ham)): \n",
    "            for y in range(len(self.ham[x][0])):\n",
    "                hamCount +=1 \n",
    "                if self.ham[x][0][y] in hamDic: \n",
    "                    hamDic[self.ham[x][0][y]] +=1\n",
    "                else: \n",
    "                    hamV +=1\n",
    "                    hamDic[self.ham[x][0][y]] =1\n",
    "        return spamDic,hamDic,np.array([[hamV,hamCount],[spamV,spamCount]])\n",
    "    \n",
    "    def fit(self,data):             #return some basic values for probability calculation\n",
    "        self.spam, self.ham = self.split_classes(data)\n",
    "        self.n = np.array([len(self.ham),len(self.spam),len(data)])\n",
    "        self.spamDic, self.hamDic, self.counts = self.create_word_dict()\n",
    "               \n",
    "    def predict(self,test) :   # predicts test data based on the fitted data\n",
    "        self.testData = test\n",
    "        predictions = []\n",
    "        \n",
    "        hamP = []\n",
    "        pY = m.log(self.n[0]/self.n[2])\n",
    "        for x in test: \n",
    "            pyx = pY\n",
    "            for y in x[0]: \n",
    "                if y in self.hamDic:\n",
    "                    pyx += m.log((self.hamDic[y]+1)/(self.counts[0][1]+self.counts[0][0]+1))\n",
    "                else: \n",
    "                    pyx += m.log((0+1)/(self.counts[0][1]+self.counts[0][0]+1))\n",
    "            hamP.append(pyx)\n",
    "        \n",
    "        spamP = []\n",
    "        pY = m.log(self.n[1]/self.n[2])\n",
    "        for x in test: \n",
    "            pyx = pY\n",
    "            for y in x[0]: \n",
    "                if y in self.spamDic:\n",
    "                    pyx += m.log((self.spamDic[y]+1)/(self.counts[1][1]+self.counts[1][0]+1))\n",
    "                else: \n",
    "                    pyx += m.log((0+1)/(self.counts[1][1]+self.counts[1][0]+1))\n",
    "            spamP.append(pyx)\n",
    "            \n",
    "        for z in range(len(spamP)):\n",
    "            if spamP[z] >= hamP[z]:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)     \n",
    "        self.predictions = predictions\n",
    "        print(\"The test data was predicted based on the model.\")\n",
    "    \n",
    "    def accuracy(self):                                            # 3 basic metrics to ecaluate the model\n",
    "        accuracy = 0\n",
    "        for x in range(len(self.predictions)): \n",
    "            if self.predictions[x] == self.testData[x][1]:\n",
    "                accuracy +=1\n",
    "        return accuracy/len(self.predictions)*100\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        conf = np.zeros((2,2), dtype=int)\n",
    "        for x in range(len(self.predictions)): \n",
    "            conf[self.predictions[x]][self.testData[x][1]] += 1\n",
    "        return conf\n",
    "    \n",
    "    def F1(self,conf):\n",
    "        precH = conf[0][0] / (conf[0][0] + conf[0][1])\n",
    "        recH = conf[0][0] / (conf[0][0] + conf[1][0])\n",
    "        precS = conf[1][1] / (conf[1][1] + conf[1][0])\n",
    "        recS = conf[1][1] / (conf[1][1] + conf[0][1])\n",
    "        F1H = (2*precH*recH) / (precH+recS)\n",
    "        F1S = (2*precS*recS) / (precH+recS)\n",
    "        return [F1H,F1S]\n",
    "        \n",
    "    def evaluate(self):                 # Calculates some basic metrics based on the results of the test data\n",
    "        print(\"The following values results were achieved for the test data:\"+ \"\\n\")\n",
    "        accuracy = self.accuracy()\n",
    "        print(\"Accuracy: \" + str(accuracy) + \"%\" +\"\\n\")\n",
    "        confusion = self.confusion_matrix()\n",
    "        print(\"Confusion Maxtrix:\")\n",
    "        print(pd.DataFrame(data=confusion,index=[\"Spam\",\"Ham\"],columns=[\"Spam\",\"Ham\"]),\"\\n\")\n",
    "        F1 = self.F1(confusion)\n",
    "        print(\"Fscores for both classes:\",pd.DataFrame(data=F1,index=[\"Spam\",\"Ham\"],columns=[\"\"]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data was predicted based on the model.\n",
      "The following values results were achieved for the test data:\n",
      "\n",
      "Accuracy: 94.4954128440367%\n",
      "\n",
      "Confusion Maxtrix:\n",
      "      Spam  Ham\n",
      "Spam   168    3\n",
      "Ham     15  141 \n",
      "\n",
      "Fscores for both classes:               \n",
      "Spam  0.919572\n",
      "Ham   0.902330\n"
     ]
    }
   ],
   "source": [
    "prep = data_tansformer(\"data/Bayes\")\n",
    "train, test = prep.split()\n",
    "bayes = naive_bayes()\n",
    "bayes.fit(train)\n",
    "bayes.predict(test)\n",
    "bayes.evaluate()\n",
    "\n",
    "    \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
