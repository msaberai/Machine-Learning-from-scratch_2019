{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "This Notebook features an implementation of a simple binary decision tree from scratch.\n",
    "\n",
    "### Problem:\n",
    "- Build a decision tree.\n",
    "- Your tree should have the variable height.\n",
    "- For each dataset plot the dependence of classification accuracy on the height of the tree.\n",
    "\n",
    "\n",
    "### Implementation features:\n",
    "- Gini coefficient as information gain measure\n",
    "- Variable tree depth\n",
    "- Optimization of tree depth for given data up to the maximum depth\n",
    "- Basic metrics and a data_prep class to preprocess the data\n",
    "\n",
    "\n",
    "### Important functions: \n",
    "- decision_tree.find_tree() : finds the optimal tree for given data and given max depth \n",
    "- decision_tree.class.predict() : predicts new data and outputs accuracy and confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preperation class \n",
    "class data_prep:                                 #Data preparation and normalization for the model \n",
    "    def __init__(self,location):\n",
    "        self.data = open(location, \"r+\")\n",
    "        self.data = self.data.read()\n",
    "        self.data = self.data.splitlines()\n",
    "        for x in range(len(self.data)):\n",
    "            self.data[x] = self.data[x].split(\" \")\n",
    "                       \n",
    "    def transform(self,numbers = \"y\"):\n",
    "        data = self.data\n",
    "        Y = []\n",
    "        del data[0]\n",
    "        del data[0]\n",
    "        for w in range(len(data)):\n",
    "            for y in range(len(data[w])):\n",
    "                data[w][y] = float(data[w][y]) \n",
    "        features = len(data[0])-1\n",
    "        for x in range(len(data)):\n",
    "            Y.append(data[x][features:])\n",
    "            data[x] = data[x][:features]\n",
    "        self.transformedX = numpy.array(data)\n",
    "        self.transformedY = (numpy.array(Y)).astype(int)\n",
    "        \n",
    "    def normalize(self):\n",
    "        features = numpy.transpose(self.transformedX)\n",
    "        toDelete = []\n",
    "        for y in range(len(features)):\n",
    "            maxi = max(features[y])\n",
    "            mini = min(features[y])\n",
    "            if maxi == mini: \n",
    "               print(\"Feature \" + str(y) + \" was spotted to be useless (Only 1 possibe value). It will be removed from the dataset\")\n",
    "               toDelete.append(y)\n",
    "            else: \n",
    "                for z in range (len(features[y])):\n",
    "                    features[y][z] =  (features[y][z]- mini)/ (maxi - mini)\n",
    "        newFeatures = []\n",
    "        for z in range(len(features)): \n",
    "            if z not in toDelete: \n",
    "                       newFeatures.append(features[z])\n",
    "        newFeatures = numpy.array(newFeatures)  \n",
    "        newFeatures = numpy.transpose(newFeatures)\n",
    "        self.normalizedY = self.transformedY\n",
    "        self.normalizedX = newFeatures               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3891\n"
     ]
    }
   ],
   "source": [
    "#Data prep:\n",
    "\n",
    "train = data_prep(\"data/tree/txt/01_train.txt\")            \n",
    "train.transform()      \n",
    "train.normalize()\n",
    "print(len(train.normalizedX))\n",
    "\n",
    "\n",
    "test = data_prep(\"data/tree/txt/01_test.txt\")\n",
    "test.transform()\n",
    "test.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree: \n",
    "    def __init__(self,X,Y, depth=10):   #initialize useful values and data\n",
    "        self.n = len(X)\n",
    "        self.X = X[int(self.n/20):]\n",
    "        self.X_val = X[:int(self.n/20)]\n",
    "        self.Y = Y[int(self.n/20):].T\n",
    "        self.Y_val = Y[:int(self.n/20)].T\n",
    "        self.n = len(self.X)\n",
    "        self.classes = max(self.Y.T)[0]\n",
    "        self.features = len(self.X.T)\n",
    "        self.maxDepth = depth\n",
    "        \n",
    "    def gini(self,dataset):    #calculate the gini coefficient for a dataset\n",
    "        count = {}\n",
    "        for x in range (self.classes):\n",
    "            count[x+1] = 0\n",
    "        for y in range (len(dataset)):\n",
    "            count[dataset[y]]+=1\n",
    "        gini = 0 \n",
    "        for z in range (self.classes):\n",
    "            gini += count[z+1]/len(dataset)* (1-count[z+1]/len(dataset))\n",
    "        return gini \n",
    "    \n",
    "    def gini_gain(self,split1,split2,originalLen): #calculate gini gain for 2 datasets\n",
    "        return self.gini(split1)*(len(split1)/originalLen) + self.gini(split2)*(len(split2)/originalLen)\n",
    "       \n",
    "    \n",
    "    def find_best_split(self,labels,data):  #searches for the best split rule for dataset\n",
    "        best_gain = 0 \n",
    "        best_question = None\n",
    "        current_uncertainty = self.gini(labels)\n",
    "        for x in range (self.features):\n",
    "            for y in range(1,100): \n",
    "                split1 = []\n",
    "                split2 = []\n",
    "                for z in range(0,len(data)):\n",
    "                    if data[z][x] <= (y/100):\n",
    "                        split1.append(labels[z])\n",
    "                    else: \n",
    "                        split2.append(labels[z])\n",
    "                if not split2: \n",
    "                    gain = 0\n",
    "                elif not split1: \n",
    "                    gain = 0\n",
    "                else:\n",
    "                    gain = self.gini_gain(split1,split2,len(data))\n",
    "                    gain = gain - current_uncertainty\n",
    "                if gain < best_gain: \n",
    "                    best_gain = gain \n",
    "                    best_question = [x,y/100]\n",
    "        return -1* best_gain ,best_question\n",
    "    \n",
    "    def get_ratio(self,label):      #helper function for leaf probabilities\n",
    "        ratio = {}\n",
    "        for x in label: \n",
    "            if x in ratio: \n",
    "                ratio[x] +=1 \n",
    "            else: \n",
    "                ratio[x] = 1\n",
    "        for key in ratio: \n",
    "            ratio[key] = ratio[key]/len(label)\n",
    "        return ratio\n",
    "    \n",
    "    def split(self,label,data,criteria):    #split dataset based on a binary rule\n",
    "        split1 = []\n",
    "        split2 = []\n",
    "        label1 = []\n",
    "        label2 = []\n",
    "        for x in range (len(data)):\n",
    "            if data[x][criteria[0]] <= criteria[1]:\n",
    "                split1.append(data[x])\n",
    "                label1.append(label[x])\n",
    "            else: \n",
    "                split2.append(data[x])\n",
    "                label2.append(label[x])\n",
    "        return numpy.array(split1), numpy.array(label1,ndmin=2), numpy.array(split2),numpy.array(label2,ndmin=2)\n",
    "            \n",
    "    def build_tree(self,label,data,depth):  #build the tree recursively from root\n",
    "        depth += 1\n",
    "        gain,question = self.find_best_split(label,data)\n",
    "        if gain == 0 or depth == self.maxDepth: \n",
    "            return self.get_ratio(label)\n",
    "        split1,label1, split2, label2 = self.split(label,data,question)\n",
    "        left = self.build_tree(label1[0], split1,depth)\n",
    "        right = self.build_tree(label2[0], split2,depth)\n",
    "        return [question,left,right]\n",
    "    \n",
    "    def find_tree(self): #find the best tree depth based on validation data\n",
    "        results = []\n",
    "        for x in range(self.maxDepth):\n",
    "            self.structure = self.build_tree(self.Y[0],self.X,x-1)\n",
    "            predictions = []\n",
    "            for x in range (len(self.X_val)):\n",
    "                prediction = self.find_prediction(self.X_val[x])\n",
    "                predictions.append(prediction)\n",
    "            results.append(self.accuracy(self.Y_val[0],predictions))\n",
    "        names = list(reversed(list(range(1, self.maxDepth+1))))\n",
    "        print(pd.DataFrame(data=results,index=names, columns=[\"Accuracy for Tree depth\"]),\"\\n\")\n",
    "        print(\"The best accuracy was found for a tree depth of \" + str(self.maxDepth - results.index(max(results))))\n",
    "        self.structure = self.build_tree(self.Y[0],self.X,results.index(max(results))-1)\n",
    "        self.depth = self.maxDepth - results.index(max(results))\n",
    "        \n",
    "    def predict(self,data,label):    #predict new data based on a decision tree\n",
    "        predictions = []\n",
    "        for x in range (len(data)):\n",
    "            prediction = self.find_prediction(data[x])\n",
    "            predictions.append(prediction)\n",
    "        accuracy = self.accuracy(label.T[0],predictions)\n",
    "        print(\"Accuracy of the predictions: \" + str(accuracy) + \"%\\n\")\n",
    "        confusion = self.confusion_matrix(label.T[0],predictions)\n",
    "        print(pd.DataFrame(data=confusion),\"\\n\")\n",
    "    \n",
    "    def find_prediction(self,data):   #predict one data example\n",
    "        decision = 0\n",
    "        tree = self.structure\n",
    "        rule = tree[0]\n",
    "        while type(tree) != dict:\n",
    "            if data[rule[0]] <= rule[1]:\n",
    "                tree = tree[1]\n",
    "                if type(tree) == dict:\n",
    "                    break\n",
    "                rule = tree[0]\n",
    "                \n",
    "                rule = tree[0]\n",
    "            else:\n",
    "                tree = tree[2] \n",
    "                if type(tree) == dict:\n",
    "                    break\n",
    "                rule = tree[0]\n",
    "        probable = 0\n",
    "        for key in tree: \n",
    "            if tree[key] > probable:\n",
    "                probable = tree[key]\n",
    "                decision = key\n",
    "        return decision\n",
    "                   \n",
    "    def accuracy(self,label,predictions):   #metrics for the results\n",
    "        accuracy = 0\n",
    "        for x in range(len(predictions)): \n",
    "            if predictions[x] == label[x]:\n",
    "                accuracy +=1\n",
    "        return accuracy/len(predictions)*100\n",
    "    \n",
    "    def confusion_matrix(self,label,predictions):\n",
    "        conf = numpy.zeros((self.classes,self.classes), dtype=int)\n",
    "        for x in range(len(predictions)): \n",
    "            conf[predictions[x]-1][label[x]-1] += 1\n",
    "        return conf      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy for Tree depth\n",
      "10                92.783505\n",
      "9                 93.298969\n",
      "8                 93.814433\n",
      "7                 94.329897\n",
      "6                 95.360825\n",
      "5                 95.360825\n",
      "4                 95.876289\n",
      "3                 96.391753\n",
      "2                 84.020619\n",
      "1                 58.247423 \n",
      "\n",
      "The best accuracy was found for a tree depth of 3\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree(train.normalizedX,train.transformedY,depth = 5)\n",
    "tree.find_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the predictions: 73.502955538422%\n",
      "\n",
      "     0   1   2   3   4   5   6   7   8    9     10   11  12  13  14  15   16  \\\n",
      "0   584   0   0   0   0   0   0   0   0   24    70  131   0   0   0  21    0   \n",
      "1     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "2     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "3     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "4     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "5     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "6     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "7     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "8     0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "9     0   0   0   0   0   0   0   0   0  311   144   91   0   0   0  25    0   \n",
      "10    0   0   0   0   0   0   0   0   0    0  1292  218   0   0   0  34    0   \n",
      "11    0   0   0   0   0   0   0   0   0    0     0  447   0   0   0  42    0   \n",
      "12    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "13    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "14    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "15    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0  49    0   \n",
      "16  116   0   0   0   0   0   0   0   0   12    38   53   0   0   0  12  177   \n",
      "17    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "18    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "19    0   0   0   0   0   0   0   0   0    0     0    0   0   0   0   0    0   \n",
      "\n",
      "    17  18  19  \n",
      "0    0   0   0  \n",
      "1    0   0   0  \n",
      "2    0   0   0  \n",
      "3    0   0   0  \n",
      "4    0   0   0  \n",
      "5    0   0   0  \n",
      "6    0   0   0  \n",
      "7    0   0   0  \n",
      "8    0   0   0  \n",
      "9    0   0   0  \n",
      "10   0   0   0  \n",
      "11   0   0   0  \n",
      "12   0   0   0  \n",
      "13   0   0   0  \n",
      "14   0   0   0  \n",
      "15   0   0   0  \n",
      "16   0   0   0  \n",
      "17   0   0   0  \n",
      "18   0   0   0  \n",
      "19   0   0   0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree.predict(test.normalizedX,test.transformedY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
